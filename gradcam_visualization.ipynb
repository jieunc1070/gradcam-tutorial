{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1RsunV4ffAAtegCuJdNJ0TiIN3qPnJQoK","timestamp":1675216828502}],"mount_file_id":"1oMwqYmVi0CFKDxRNJ0jmNWskP0p5eKDX","authorship_tag":"ABX9TyPv6cuFFDzWPflTY/gxqkdM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["런타임 유형 GPU로 변경"],"metadata":{"id":"IE7F0rMOJjkM"}},{"cell_type":"code","source":["%cd drive/MyDrive/gradcam-visualization/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hwIYAbEeJOdA","executionInfo":{"status":"ok","timestamp":1675241632530,"user_tz":-540,"elapsed":6,"user":{"displayName":"최지은","userId":"03115347191875421588"}},"outputId":"f152953d-e073-42ba-cb44-d250a434a56e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/gradcam-visualization\n"]}]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKiuKALbJskM","executionInfo":{"status":"ok","timestamp":1675241632531,"user_tz":-540,"elapsed":5,"user":{"displayName":"최지은","userId":"03115347191875421588"}},"outputId":"51f6a9cf-f370-4547-a95f-1bc294a0c7a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34m_examples\u001b[0m/                   \u001b[01;34mpytorch_grad_cam\u001b[0m/  \u001b[01;34m_results\u001b[0m/\n","gradcam_visualization.ipynb  README.md\n"]}]},{"cell_type":"markdown","source":["라이브러리 설치 및 불러오기"],"metadata":{"id":"2IOj69FpKi6Q"}},{"cell_type":"code","source":["!pip install timm\n","!pip install ttach"],"metadata":{"id":"lEpnbVB4tVq-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675241645684,"user_tz":-540,"elapsed":13156,"user":{"displayName":"최지은","userId":"03115347191875421588"}},"outputId":"c1d49885-2135-40da-c16d-2e93cbbf5516"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting timm\n","  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.1+cu116)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.4.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (2.25.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (7.1.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n","Installing collected packages: huggingface-hub, timm\n","Successfully installed huggingface-hub-0.12.0 timm-0.6.12\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ttach\n","  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n","Installing collected packages: ttach\n","Successfully installed ttach-0.0.3\n"]}]},{"cell_type":"code","source":["import math\n","import os\n","import argparse\n","import cv2\n","import numpy as np\n","import torch\n","import timm\n","\n","from pytorch_grad_cam import GradCAM, \\\n","    ScoreCAM, \\\n","    GradCAMPlusPlus, \\\n","    AblationCAM, \\\n","    XGradCAM, \\\n","    EigenCAM, \\\n","    EigenGradCAM, \\\n","    LayerCAM, \\\n","    FullGrad\n","from pytorch_grad_cam.utils.image import show_cam_on_image, \\\n","    preprocess_image\n","from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n","from pytorch_grad_cam.ablation_layer import AblationLayerVit"],"metadata":{"id":"tOWgBS7wi0Zb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["사용 가능한 pretrained model list 확인"],"metadata":{"id":"j47T-wxKKqnd"}},{"cell_type":"code","source":["timm.list_models('convnext*')"],"metadata":{"id":"rHvfG1BnjnK5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["timm.list_models('resnet*')"],"metadata":{"id":"R41mcIHpNWRB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["테스트 이미지 및 method 설정"],"metadata":{"id":"ov80NseftTgD"}},{"cell_type":"code","source":["def get_args():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--use-cuda', action='store_true', default=True,\n","                        help='Use NVIDIA GPU acceleration')\n","    parser.add_argument(\n","        '--image-path',\n","        type=str,\n","        default='_examples',\n","        help='Input image folder name')\n","    parser.add_argument(\n","        '--image-name',\n","        type=str,\n","        default='horses.jpeg',\n","        help='Input image file name')\n","    parser.add_argument('--aug_smooth', action='store_true',\n","                        help='Apply test time augmentation to smooth the CAM')\n","    parser.add_argument(\n","        '--eigen_smooth',\n","        action='store_true',\n","        help='Reduce noise by taking the first principle componenet'\n","        'of cam_weights*activations')\n","    parser.add_argument(\n","        '--method',\n","        type=str,\n","        default='gradcam',\n","        choices=['gradcam', 'gradcam++', 'scorecam', 'xgradcam', 'ablationcam',\n","                 'eigencam', 'eigengradcam', 'layercam', 'fullgrad'])\n","\n","    args = parser.parse_args(args=[])\n","    args.use_cuda = args.use_cuda and torch.cuda.is_available()\n","    if args.use_cuda:\n","        print('Using GPU for acceleration')\n","    else:\n","        print('Using CPU for computation')\n","\n","    return args"],"metadata":{"id":"HcCnOg6gtOWU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["tensor를 (B, C, H, W) shape으로 변환하는 함수"],"metadata":{"id":"DXZLlIIytaaL"}},{"cell_type":"code","source":["def reshape_transform(tensor):\n","    # convnext torch.Size([1, 768, 7, 7])\n","    # resnet18 torch.Size([1, 512, 7, 7])\n","    # resnet50 torch.Size([1, 2048, 7, 7])\n","    # Wide_resnet50 torch.Size([1, 2048, 7, 7])\n","    # ResNext50 torch.Size([1, 2048, 7, 7])\n","    \n","    if len(tensor.size()) == 4:\n","      if tensor.size(1) == tensor.size(2):\n","        # tensor shape이 아래와 같이 [B, H, W, C]\n","        # ex) tensor.shape = torch.Size([1, 7, 7, 768])\n","        result = tensor.transpose(2, 3).transpose(1, 2)\n","        # result.shape = torch.Size([1, 768, 7, 7])\n","      elif tensor.size(2) == tensor.size(3):\n","        # tensor shape이 아래와 같이 [B, C, H, W]\n","        # ex) tensor.shape = torch.Size([1, 768, 7, 7])\n","        result = tensor\n","\n","    elif len(tensor.size()) == 3:\n","      if math.sqrt(tensor.size(1)) % 1 == 0:\n","        height = width = int(math.sqrt(tensor.size(1)))\n","        result = tensor.reshape(tensor.size(0),\n","                                height, width, tensor.size(2))\n","      else:\n","        height = width = int(math.sqrt(tensor.size(1)-1))\n","        result = tensor[:, 1:, :].reshape(tensor.size(0),\n","                                          height, width, tensor.size(2))\n","      result = result.transpose(2, 3).transpose(1, 2)\n","    \n","    return result"],"metadata":{"id":"VnxzBQzZtZun"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8kT4Ft9Gs-qB","executionInfo":{"status":"ok","timestamp":1675243256325,"user_tz":-540,"elapsed":6826,"user":{"displayName":"최지은","userId":"03115347191875421588"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a13568db-930c-4690-d68d-7f34a0693dc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using GPU for acceleration\n"]}],"source":["if __name__ == '__main__':\n","    \"\"\" python swinT_example.py -image-path <path_to_image>\n","    Example usage of using cam-methods on a SwinTransformers network.\n","    \"\"\"\n","\n","    args = get_args()\n","    methods = \\\n","        {\"gradcam\": GradCAM,\n","         \"scorecam\": ScoreCAM,\n","         \"gradcam++\": GradCAMPlusPlus,\n","         \"ablationcam\": AblationCAM,\n","         \"xgradcam\": XGradCAM,\n","         \"eigencam\": EigenCAM,\n","         \"eigengradcam\": EigenGradCAM,\n","         \"layercam\": LayerCAM,\n","         \"fullgrad\": FullGrad}\n","\n","    if args.method not in list(methods.keys()):\n","        raise Exception(f\"method should be one of {list(methods.keys())}\")\n","\n","    rgb_img = cv2.imread(os.path.join(args.image_path, args.image_name), 1)\n","    org_img = cv2.resize(rgb_img, (224, 224))\n","    rgb_img = rgb_img[:, :, ::-1]\n","    rgb_img = cv2.resize(rgb_img, (224, 224))\n","    rgb_img = np.float32(rgb_img) / 255\n","    input_tensor = preprocess_image(rgb_img,\n","                                    mean=[0.5, 0.5, 0.5],\n","                                    std=[0.5, 0.5, 0.5])\n","    \n","    for model_name in [\"ResNet50\", \"ViT\", \"SwinT\", \"ConvNext\"]:\n","      if model_name == \"ResNet50\":\n","        model = timm.create_model('resnet50', pretrained=True)\n","        target_layers = [model.layer4]\n","      elif model_name == \"ViT\":\n","        model = timm.create_model('vit_base_patch16_224', pretrained=True)\n","        target_layers = [model.blocks[-1].norm1]\n","      elif model_name == \"SwinT\":\n","        model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n","        target_layers = [model.layers[-1].blocks[-1].norm2]\n","      elif model_name == \"ConvNext\":\n","        model = timm.create_model('convnext_base', pretrained=True)\n","        target_layers = [model.stages[-1].blocks[-1].norm]\n","      \n","      model.eval()\n","\n","      if args.use_cuda:\n","          model = model.cuda()\n","\n","      if args.method not in methods:\n","          raise Exception(f\"Method {args.method} not implemented\")\n","\n","      if args.method == \"ablationcam\":\n","          cam = methods[args.method](model=model,\n","                                    target_layers=target_layers,\n","                                    use_cuda=args.use_cuda,\n","                                    reshape_transform=reshape_transform,\n","                                    ablation_layer=AblationLayerVit())\n","      else:\n","          cam = methods[args.method](model=model,\n","                                    target_layers=target_layers,\n","                                    use_cuda=args.use_cuda,\n","                                    reshape_transform=reshape_transform)\n","\n","      # AblationCAM and ScoreCAM have batched implementations.\n","      # You can override the internal batch size for faster computation.\n","      cam.batch_size = 32\n","\n","      # 특정 class C에 대한 결과를 확인하려면 아래와 같이 설정\n","      # targets=[ClassifierOutputTarget(C의 class index)]\n","      # targets=None이면 classification score가 가장 높은 클래스에 대한 결과를 보여줌\n","      grayscale_cam = cam(input_tensor=input_tensor,\n","                          targets=None,\n","                          eigen_smooth=args.eigen_smooth,\n","                          aug_smooth=args.aug_smooth)\n","\n","      # Here grayscale_cam has only one image in the batch\n","      grayscale_cam = grayscale_cam[0, :]\n","\n","      cam_image = show_cam_on_image(rgb_img, grayscale_cam)\n","      org_img = np.hstack((org_img, cam_image))\n","\n","    cv2.imwrite('_results/result_{}.jpg'.format(args.image_name.split(\".\")[0]),\n","                org_img)"]}]}